\documentclass[leqno]{article}
\usepackage[utf8x]{inputenc}
\usepackage{float}
\usepackage[brazil]{babel} %\usepackage[latin1]{inputenc}
\usepackage{a4wide}
\usepackage{mathtools}
\usepackage{nccmath}
\setlength{\oddsidemargin}{-0.2in}
% % \setlength{\oddsidemargin}{0.2in}
\setlength{\evensidemargin}{-0.2in}
% % \setlength{\evensidemargin}{0.5in}
% % \setlength{\textwidth}{5.5in}
\setlength{\textwidth}{6.5in}
\setlength{\topmargin}{-1.2in}
\setlength{\textheight}{10in}
\usepackage[]{amsfonts} \usepackage[]{amsmath}
\usepackage[]{amssymb} \usepackage[]{latexsym}
\usepackage{graphicx,color} \usepackage{amsthm}
\usepackage{mathrsfs} \usepackage{url}
\usepackage{cancel} \usepackage{enumerate}
\usepackage{xifthen} \usepackage{tikz}
\usetikzlibrary{automata,arrows,positioning,calc}
\usepackage{listings}
\usepackage{tcolorbox}
\numberwithin{equation}{section}

\setlength{\parindent}{12 pt}

\definecolor{codegray}{rgb}{0.9, 0.9, 0.9}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{codegreen}{rgb}{0,0.6,0}

\lstdefinestyle{mystyle}{
	language=Scilab,
	backgroundcolor=\color{codegray},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	emph={testfunc,print,src},
	emphstyle=\color{codeyellow},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}

\lstset{style=mystyle}

\begin{document}
	
	\newtheorem{teo}{Teorema}[section] \newtheorem*{teo*}{Teorema}
	\newtheorem{prop}[teo]{ProposiÃ§Ã£o} \newtheorem*{prop*}{ProposiÃ§Ã£o}
	\newtheorem{lema}[teo]{Lemma} \newtheorem*{lema*}{Lema}
	\newtheorem{cor}[teo]{CorolÃ¡rio} \newtheorem*{cor*}{CorolÃ¡rio}
	
	\theoremstyle{definition}
	\newtheorem{defi}[teo]{DefiniÃ§Ã£o} \newtheorem*{defi*}{DefiniÃ§Ã£o}
	\newtheorem{exem}[teo]{Exemplo} \newtheorem*{exem*}{Exemplo}
	\newtheorem{obs}[teo]{ObservaÃ§Ã£o} \newtheorem*{obs*}{ObservaÃ§Ã£o}
	\newtheorem*{hipo}{HipÃ³teses}
	\newtheorem*{nota}{NotaÃ§Ã£o}
	
	\newcommand{\ds}{\displaystyle} \newcommand{\nl}{\newline}
	\newcommand{\eps}{\varepsilon} \newcommand{\ssty}{\scriptstyle}
	\newcommand{\bE}{\mathbb{E}}
	\newcommand{\cB}{\mathcal{B}}
	\newcommand{\cF}{\mathcal{F}}
	\newcommand{\cA}{\mathcal{A}}
	\newcommand{\cM}{\mathcal{M}}
	\newcommand{\cD}{\mathcal{D}}
	\newcommand{\cN}{\mathcal{N}}
	\newcommand{\cL}{\mathcal{L}}
	\newcommand{\cLN}{\mathcal{LN}}
	\newcommand{\bP}{\mathbb{P}}
	\newcommand{\bQ}{\mathbb{Q}}
	\newcommand{\bN}{\mathbb{N}}
	\newcommand{\bR}{\mathbb{R}}
	\newcommand{\bZ}{\mathbb{Z}}
	
	\newcommand{\bfw}{\mathbf{w}}
	\newcommand{\bfv}{\mathbf{v}}
	\newcommand{\bfu}{\mathbf{u}}
	\newcommand{\bfx}{\mathbf{x}}
	\newcommand{\bfb}{\mathbf{b}}
	
	\newcommand{\bvecc}[2]{%
		\begin{bmatrix} #1 \\ #2  \end{bmatrix}
	}
	\newcommand{\bveccc}[3]{%
		\begin{bmatrix} #1 \\ #2 \\ #3  \end{bmatrix}
	}
	
	\newenvironment{sol} 
	{
		\vspace{4mm}
		\noindent\textbf{{\large CÃ³digo:}}
		\strut\newline
		\smallskip
		\hspace{-3.5mm} 
	} 
	% Objetos que aparecem *apÃ³s* o ambiente. 
	% (vocÃª pode, por exemplo, modificar, 
	% ou remover, a barra horizontal} 
	%{\noindent\rule{4cm}{.1mm}}
	
	
	\title{Ãlgebra Linear - Aula PrÃ¡tica 4}
	
	\author{Iara Cristina Mescua Castro}
	
	\date{\today}
	
	\maketitle 
	
	\begin{enumerate}
		
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		%%%%%%%%%%%%%%%%%%%%%% ExercÃ­cio 1 %%%%%%%%%%%%%%%%%%%%%%
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		
		\item  \textbf{{\large MÃ‰TODO DOS MÃNIMOS QUADRADOS}}\\
	
		
		\begin{tcolorbox}[colback=green!5,colframe=green!40!black]
			1) (Texto do livro CÃ¡lculo - Volume 2 â€“ James Stewart) Em 1928, Charles
			Cobb e Paul Douglas publicaram um estudo no qual modelaram o
			crescimento da economia norte-americana durante o perÃ­odo de 1899-
			1922. Eles consideraram uma visÃ£o simplificada da economia em que a
			saÃ­da da produÃ§Ã£o Ã© determinada pela quantidade de trabalho envolvido e
			pela quantidade de capital investido. Apesar de existirem muitos outros
			fatores afetando o desempenho da economia, o modelo mostrou-se
			bastante preciso. A funÃ§Ã£o utilizada para modelar a produÃ§Ã£o era da forma:
			
			$$ð‘ƒ = bL^{\alpha}K^{1 - \alpha}$$
			
			onde P Ã© a produÃ§Ã£o total (valor monetÃ¡rio dos bens produzidos no ano);
			L Ã© a quantidade de trabalho (nÃºmero total de pessoas-hora trabalhadas no
			ano); e K Ã© a quantidade de capital investido (valor monetÃ¡rio das
			mÃ¡quinas, equipamentos e prÃ©dios); b e $\alpha$ sÃ£o parÃ¢metros (constantes) a
			serem determinados.
			Cobb e Douglas usaram os dados da tabela a seguir e o MÃ©todo dos
			MÃ­nimos Quadrados para obter os valores de b e de $\alpha$.
		\end{tcolorbox}
		
		\begin{tcolorbox}[colback=gray!5,colframe=gray!40!black]	
			a) FaÃ§a como Cobb e Douglas: use o MÃ©todo dos MÃ­nimos Quadrados
			para estimar os valores dos parÃ¢metros b e $\alpha$. Mostre a sua modelagem
			para o problema ser resolvido pelo MÃ©todo dos MÃ­nimos Quadrados.
		\end{tcolorbox}		
	
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		%%%%%%%%%%%%%%%%%%%%%% ALGORITMO 1 %%%%%%%%%%%%%%%%%%%%%%
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		
		\textbf{{\normalsize DESENVOLVIMENTO}}
		
		Queremos encontrar b e $\alpha$ a partir da fÃ³rmula, entÃ£o para isso vamos tentar isolÃ¡-los:
		$$ð‘ƒ = bL^{\alpha}K^{1 - \alpha}$$
		Calculando logaritmo da equaÃ§Ã£o:
		$$ln(ð‘ƒ) = ln(b) + \alpha ln(L) + (1-\alpha)ln(K)$$
		$$ln(ð‘ƒ) = ln(b) + \alpha ln(L) + ln(K) - \alpha ln(K)$$
		$$ln(ð‘ƒ) - ln(K) = ln(b) + \alpha ln(L) - \alpha ln(K)$$
		
		$$ln(b) + \alpha (ln(L) - ln(K)) = ln(ð‘ƒ) - ln(K)$$
		
		Para utilizar o mÃ©todo dos mÃ­nimos quadrados, precisamos de expressÃ£o na forma $Ax = b$.
		Podemos observar que $ln(b)$ nÃ£o estÃ¡ multiplicando com ninguÃ©m, entÃ£o podemos colocar uma coluna de 1 na frente de $A = (ln(L) - ln(K))$ para representÃ¡-la da seguinte forma:
		
		
		$$\begin{bmatrix}
			1 & (ln(L) - ln(K))^1 \\
			1 & \vdots \\
			1 & (ln(L) - ln(K))^{24}
		\end{bmatrix}
		\begin{bmatrix}
			ln(b) \\
			\alpha
		\end{bmatrix} = \begin{bmatrix}
			(ln(P) - ln(K))^1 \\
			\vdots \\
			(ln(P) - ln(K))^{24}
		\end{bmatrix}$$
	
	Agora podemos aplicar o mÃ©todo dos mÃ­nimos quadrados, onde:
	
	$$A = \begin{bmatrix}
		1 & (ln(L) - ln(K))^1 \\
		1 & \vdots \\
		1 & (ln(L) - ln(K))^{24}
	\end{bmatrix}$$

	$$x = \begin{bmatrix}
		ln(b) \\
		\alpha
	\end{bmatrix}$$

	$$b = \begin{bmatrix}
		(ln(P) - ln(K))^1 \\
		\vdots \\
		(ln(P) - ln(K))^{24}
	\end{bmatrix}$$

	Logo:
	
		$$ln(b) + \alpha (ln(L) - ln(K)) = ln(ð‘ƒ) - ln(K)$$
		
		$$Ax = b$$
		
	Criando uma funÃ§Ã£o que receba a planilha de dados e separe as colunas K, L e P para transformÃ¡-las nas matrizes A e b do sistema, e por fim, calcular a soluÃ§Ã£o x que melhor aproxima esses dados atravÃ©s do mÃ©todo dos mÃ­nimos quadrados:
	
	$$A^TAx = A^Tb$$
	
	Lembrando que ao encontrar x, teremos os valores de $ln(b)$ e $\alpha$, $$x = \begin{bmatrix}
		ln(b) \\
		\alpha
	\end{bmatrix}$$
	EntÃ£o para retornar b, basta elevar o primeiro valor do vetor x, $ln(b)$ a exponencial:
	
\begin{sol}			
	\begin{lstlisting}[style=mystyle, language=Scilab]
	function [alfa, b]=calcular_alfa_b(A)
	
	P = A(:,2);
	L = A(:,3);
	K = A(:,4);
	
	P_ln = log(P);
	L_ln = log(L);
	K_ln = log(K);
	
	n = size(L,1);
	A = [ones(n,1) (L_ln - K_ln)];
	b = (P_ln - K_ln);
	//nao esquecer de executar a funcao Gaussian_Elimination_4
	x = Gaussian_Elimination_4(A' * A, A' * b);
	alfa = x(2);
	b = exp(x(1));
	endfunction
	\end{lstlisting}
	\newpage
	Ao testar a funÃ§Ã£o na tabela:
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.7\linewidth]{figures/tabela}
	\end{figure}

	\begin{figure}[H]
		\centering
		\includegraphics[width=0.4\linewidth]{figures/1a}
	\end{figure}

	Encontramos que:\\
	$\cdot$ $\alpha = 0.7446062$\\
	$\cdot$ $b = 1.0070689$
	\begin{tcolorbox}[colback=gray!5,colframe=gray!40!black]	
		b) Agora, use a funÃ§Ã£o de Cobb-Douglas encontrada no item a) e teste a
		sua adequaÃ§Ã£o calculando os valores da produÃ§Ã£o nos anos de 1910 e
		1920. Comente!
	\end{tcolorbox}
	
	Agora que temos os valores de $\alpha$ e b, podemos substituÃ­-los na fÃ³rmula de produÃ§Ã£o para encontrar a previsÃ£o de P. Para isso criei uma funÃ§Ã£o que recebe a tabela de dados, e verifica o ano de entrada para escolher os valores de K e L em suas respectivas colunas, e por Ãºltimo, substituir na fÃ³rmula.
	
	\begin{lstlisting}[style=mystyle, language=Scilab]
function [P]=calcular_p(A, ano)

L = A(:,3); //L na coluna 3
K = A(:,4); //K na coluna 4

n = size(K,1) 
for i = 1:n
	if (A(i,1) == ano) //verifica a linha do ano selecionado
		x = A(i,:);
		L = x(3);
		K = x(4);
		//funcao utilizada para modelar a producao
		P = b * L^alfa * K^(1-alfa); 
	end
end
endfunction
	\end{lstlisting}
\end{sol}

Os valores de \textit{alfa} e \textit{b} nÃ£o precisam estar na entrada, pois as variÃ¡veis no scilab sÃ£o globais, basta haver executado $[alfa, b]=calcular\_alfa\_b(A)$ anteriormente. Da seguinte forma, podemos encontrar os valores de P nos anos de 1910 e 1920, e em qualquer outro ano desejado.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.4\linewidth]{figures/1b}
\end{figure}

Os valores previstos para P foram:\\
$\cdot$ $P_{1910} = 161.76185$\\
$\cdot$ $P_{1920} = 236.07215$\\

Os valores reais de P nesses anos foram:\\
$\cdot$ $P_{1910} = 159$\\
$\cdot$ $P_{1920} = 231$\\

Podemos concluir que os valores de $\alpha$ e $b$ calculam a produÃ§Ã£o de forma relativamente precisa. Vamos calcular mais alguns anos:

\begin{figure}[H]
	\centering
	\includegraphics[width=0.3\linewidth]{figures/1btestes}
\end{figure}
\newpage
Os valores previstos para P foram:\\
$\cdot$ $P_{1900} = 106.25302$\\
$\cdot$ $P_{1905} = 131.65873$\\
$\cdot$ $P_{1915} = 180.04169$\\
$\cdot$ $P_{1918} = 235.90134$\\

Os valores reais de P nesses anos foram:\\
$\cdot$ $P_{1900} = 101$\\
$\cdot$ $P_{1905} = 143$\\
$\cdot$ $P_{1915} = 189$\\
$\cdot$ $P_{1918} = 223$\\

De forma geral, a previsÃ£o estÃ¡ proxima, hÃ¡ um erro de mais ou menos 10. Segue o grÃ¡fico feito em excel dos valores reais de produÃ§Ã£o juntamente com os valores obtidos da funÃ§Ã£o de previsÃ£o ao longo dos anos:

\begin{figure}[H]
	\centering
	\includegraphics[width=1.1\linewidth]{figures/excel}
\end{figure}

Ao comparar a linha de tendÃªncia dos valores previstos de produÃ§Ã£o com a dos valores reais, nota-se que com o passar dos anos a precisÃ£o vai diminuindo.
 \newpage
\item  \textbf{{\large â€œMACHINE LEARNINGâ€}}\\

\begin{tcolorbox}[colback=green!5,colframe=green!40!black]
	2) Agora vamos usar o mÃ©todo dos mÃ­nimos quadrados para implementar um
	mÃ©todo rudimentar de â€œmachine learningâ€ para diagnosticar cÃ¢ncer de
	mama a partir de um conjunto de caracterÃ­sticas fornecidas para cada
	paciente. SÃ£o dados dois arquivos: um arquivo para â€œtreinamentoâ€
	(cancer\_train.csv) do modelo e um arquivo para â€œtesteâ€ (cancer\_test.csv).
	O primeiro arquivo contÃ©m 300 registros e o segundo 260 registros, partes
	do â€œWiscosin Diagnostic Breast Cancer datasetâ€. Cada registro de cada
	arquivo contÃ©m 11 valores: os 10 primeiros correspondem a valores reais
	de 10 caracterÃ­sticas dos nÃºcleos celulares observados em imagens
	digitalizadas de uma fina camada de massa mamÃ¡ria coletada de cada
	paciente. O dÃ©cimo primeiro valor Ã© +1 se a paciente tem cÃ¢ncer de mama
	e -1, caso contrÃ¡rio.
	Sendo x o vetor das 10 caracterÃ­sticas de cada paciente (variÃ¡veis
	independentes) e y o valor (+1 ou -1) que indica o diagnÃ³stico (variÃ¡vel
	dependente), a ideia Ã©, usando o arquivo de treinamento, obter o hiperplano
	y = h(x) que â€œmelhor se ajuste aos dados fornecidosâ€ usando o mÃ©todo dos mÃ­nimos quadrados.
	Uma vez obtido o hiperplano, o mesmo serÃ¡ usado para classificar cada
	paciente da seguinte forma: se $h(x) \geq 0$, entÃ£o o diagnÃ³stico Ã© +1 (tem
	cÃ¢ncer), caso contrÃ¡rio, o diagnÃ³stico Ã© âˆ’1 (nÃ£o tem cÃ¢ncer).
	Use o seu classificador (hiperplano) e calcule a porcentagem de acertos
	sobre o arquivo de treinamento (de certa forma Ã© uma medida do ajuste do
	seu modelo aos dados de treinamento) e sobre o arquivo de teste (de certa
	forma Ã© uma medida da capacidade de generalizaÃ§Ã£o do seu modelo).
	Construa uma Matriz de ConfusÃ£o (Confusion Matrix) (pesquise a respeito)
	com o conjunto de teste e calcule as diversas medidas daÃ­ decorrentes, tais
	como: acurÃ¡cia, precisÃ£o, recall, probabilidade de falso alarme,
	probabilidade de falsa omissÃ£o de alarme. Interprete essas medidas e
	comente os resultados obtidos.
\end{tcolorbox}	

Para essa questÃ£o vamos precisar classificar os pacientes da tabela de testes atravÃ©s de previsÃµes seguindo o classificador h(x). Ele provÃ©m do $alfa\_tr$ que serÃ¡ calculado pela tabela de treinamento.

Para calcular $alfa\_tr$, criei uma funÃ§Ã£o $[alfa\_barra]=Encontra\_alfa\_barra(x\_tr, y\_tr)$ que encontra uma soluÃ§Ã£o aproximada resolvendo o sistema linear Ax = b pelo mÃ©todo dos mÃ­nimos quadrados, onde:

$$A = x_tr' * x_tr$$

$$b = x_tr' * y_tr$$

EntÃ£o para isso, precisamos encontrar $x\_tr$ e $y\_tr$ primeiro.\\
Calculando todos os dados necessÃ¡rios, juntamente com o alfa: $y\_tr, y\_tt, x\_tr, x\_tt, alfa\_tr, h\_tr$:\\

\begin{sol}
	\begin{lstlisting}[style=mystyle, language=Scilab]
function [y_tr, y_tt, x_tr, x_tt, alfa_tr, h_tr]=dados(A_tr, A_tt)
n = size(A_tr,2);

y_tr = A_tr(:,n);
y_tt = A_tt(:,n);

x_tr = [ones(y_tr) A_tr(:,1:n - 1)];
x_tt = [ones(y_tt) A_tt(:,1:n - 1)];

alfa_tr =Encontra_alfa_barra(x_tr, y_tr);
h_tr = x_tr * alfa_tr;
endfunction

function [alfa_barra]=Encontra_alfa_barra(x_tr, y_tr)
alfa_barra = Gaussian_Elimination_4(x_tr' * x_tr, x_tr' * y_tr);
endfunction
\end{lstlisting}	

Agora jÃ¡ obtemos $alfa\_tr$ e podemos encontrar as previsÃµes para a tabela de testes (e treinamento, para comparaÃ§Ã£o), que jÃ¡ teve seus $x\_tt$ e $y\_tt$ obtidos na funÃ§Ã£o anterior $[y\_tr, y\_tt, x\_tr, x\_tt, alfa\_tr, h\_tr]=dados(A\_tr, A\_tt)$:

Agora com outra funÃ§Ã£o de encontrar o nÃºmero de acertos, multiplicamos $x\_tr$ e $x\_tt$ pelo $alfa\_tr$ obtido.
Para conferir essa previsÃ£o, basta multiplicar ela pelos resultados reais. Lembrando que se a previsÃ£o estÃ¡ certa, teremos
pacientes doentes (+1) sendo classificados com um valor \textbf{positivo}, e pacientes nÃ£o-doentes (-1) sendo classificados com um valor \textbf{negativo}. 

Note que em ambos casos em que a previsÃ£o funciona os sinais sÃ£o iguais, logo, o seu produto sempre serÃ¡ positivo. Ao multiplicar esses dois valores: $prev\_tr$ e $prev\_tt$ por $y\_tr$ e $y\_tt$, respectivamente, podemos conferir se a previsÃ£o estÃ¡ correta, checando quantos deles sÃ£o positivos.

A funÃ§Ã£o seguinte calcula a previsÃ£o e o nÃºmero de acertos da tabela de treinamento e da tabela de testes:
\begin{lstlisting}[style=mystyle, language=Scilab]
[prev_tr,prev_tt,acertos_tr, acertos_tt]=acertos(x_tr, x_tt, alfa_tr)
prev_tr = x_tr*alfa_tr;
prev_tt = x_tt*alfa_tr;

conf_prev_tr = prev_tr .*y_tr;
conf_prev_tt = prev_tt .*y_tt;

acertos_tr = sum(conf_prev_tr > 0 | conf_prev_tr == 0);
acertos_tt = sum(conf_prev_tt > 0 | conf_prev_tt == 0);
endfunction
\end{lstlisting}

Testando ambas funÃ§Ãµes, primeiro encontramos os dados necessÃ¡rios e depois calculamos os acertos com a funÃ§Ã£o acima:

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{figures/2.1}
\end{figure}

ConcluÃ­mos que com $alfa\_tr$ teve 289 acertos de 300 casos na tabela de treinamento, enquanto na tabela de testes teve apenas 185 acertos de 260 casos.

Note que $y\_tt$, $y\_tr$, $prev\_tt$ e $prev\_tt$ nÃ£o foram utilizados ainda, mas serÃ£o importantes para encontrar a matriz de confusÃ£o.

	\item  \textbf{{\large MATRIZ DE CONFUSÃƒO}}\\
	
	Para encontrar a matriz de confusÃ£o, optei tambÃ©m por criar uma funÃ§Ã£o que gerasse cada valor a partir das previsÃµes do teste \textit{'prev\_tt'} e os resultados reais em \textit{'y\_tt'}
	
	Sabemos que cada caso na previsÃ£o mantÃ©m a ordem dos valores obtidos da planilha de dados, entÃ£o basta usar cada Ã­ndice para comparar se o seu valor em \textit{'prev\_tt'} Ã© maior ou menor que 0, e checar se naquele Ã­ndice de \textit{'y\_tt'} Ã© igual a +1 ou -1.
	
	$\cdot$ VP: $h(x) > 0$ e y(i) = 1 \\
	$\cdot$ VN: $h(x) < 0$ e y(i) = -1\\
	$\cdot$ FN: $h(x) > 0$ e y(i) = -1\\
	$\cdot$ FP: $h(x) < 0$ e y(i) = 1 \\
\newpage
	\begin{lstlisting}[style=mystyle, language=Scilab]
function [VP, VN, FN, FP]=check(prev_tt, y_tt)

[VP]=check_pos(prev_tt, y_tt); //verdadeiro positivo: 1
[VN]=check_neg(prev_tt, y_tt); //verdadeiro negativo: 2
[FN]=check_neg_pos(prev_tt, y_tt); //falso negativo: 3
[FP]=check_pos_neg(prev_tt, y_tt); //falso positivo: 4

endfunction

function [VP]=check_pos(prev_tt, y_tt) //1: diz que tem, e tem mesmo
n = size(prev_tt, 1);
VP = 0;
for i = 1:n
	if (prev_tt(i) > 0 & y_tt(i) == 1)
		VP = VP + 1;
	end
end
endfunction

function [VN]=check_neg(prev_tt, y_tt) //2: diz que nao tem, e nao tem
n = size(prev_tt, 1);
VN = 0;
for i = 1:n
	if (prev_tt(i) < 0 & y_tt(i) == -1)
		VN = VN + 1;
	end
end
endfunction

function [FN]=check_neg_pos(prev_tt, y_tt) //3: diz que tem, mas nao tem
n = size(prev_tt, 1);
FN = 0;
for i = 1:n
	if (prev_tt(i) > 0 & y_tt(i) == -1)
		FN = FN + 1;
	end
end
endfunction

function [FP]=check_pos_neg(prev_tt, y_tt) //4: diz que nao tem, mas tem 
n = size(prev_tt, 1);
FP = 0;
for i = 1:n
	if (prev_tt(i) < 0 & y_tt(i) == 1)
		FP = FP + 1;
	end
end
endfunction
	\end{lstlisting}	
\end{sol}

	\begin{figure}[H]
		\centering
		\includegraphics[width=0.7\linewidth]{figures/check}
	\end{figure}
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=1\linewidth]{figures/matriz_de_confusao}
	\end{figure}

	Com essa matriz, podemos calcular outras medidas e fazer algumas anÃ¡lises:
	
	$\cdot$ \textbf{{\large AcurÃ¡cia:}}
	O cÃ¡lculo da acurÃ¡cia se dÃ¡ pela fÃ³rmula: $\frac{VP + VN}{total}$, ou seja, o total de acertos (soma da diagonal da matriz) dividido pelo total:
	
	$$\frac{185}{260} = 0.7115385 = 71.1\% $$
	
	$\cdot$ \textbf{{\large PrecisÃ£o:}} 
	O cÃ¡lculo da precisÃ£o se dÃ¡ pela fÃ³rmula: $\frac{VP}{VP + FP}$, ou seja, o total de acertos/alarmes de pessoas doentes pelo total de pessoas doentes esperadas pela previsÃ£o:
	
	$$\frac{60}{60 + 75} = 0.4444444 = 44.4\% $$
	
	Houve $44\%$, ou seja, de todas as pessoas esperadas doentes, um pouco mais da metade delas, na verdade nÃ£o tinha cÃ¢ncer. A precisÃ£o na matriz de testes foi baixa.
	
	$\cdot$ \textbf{{\large Recall ou RevocaÃ§Ã£o:}} 
	O cÃ¡lculo da recall se dÃ¡ pela fÃ³rmula: $\frac{VP}{VP + FN}$, ou seja, o total de acertos/alarmes de pessoas doentes pelo total de pessoas que realmente estÃ£o doentes:
	
	$$\frac{60}{60 + 0} = 1 = 100\% $$
	
	Houve $100\%$ de precisÃ£o, isso significa que a previsÃ£o nÃ£o deu negativo $NENHUMA$ vez para alguÃ©m que realmente tinha cÃ¢ncer. 
	
	$\cdot$ \textbf{{\large Falso Alarme:}}
	O cÃ¡lculo de falso alarme se dÃ¡ pela fÃ³rmula: $\frac{FP}{VP + FP}$, ou seja, o total de pessoas que foram esperadas com cÃ¢ncer, mas na verdade nÃ£o tinham, dividido pelo total de alarmes positivos.
	
	$$\frac{75}{75 + 60} = 0.5555556 = 55.5\% $$
	
	Houve $55\%$ de probabilidade de falsos alarmes, ou seja, cerca de metade das pessoas esperadas com cÃ¢ncer pela previsÃ£o, na verdade nÃ£o tinham cÃ¢ncer. Note que a probabilidade de falso alarme Ã© complementar Ã  precisÃ£o.
	
	$\cdot$ \textbf{{\large Falsa OmissÃ£o de Alarme:}} 
	O cÃ¡lculo da falsa omissÃ£o de alarme se dÃ¡ pela fÃ³rmula: $\frac{FN}{FN + VN}$, ou seja, o total de pessoas que tinham cÃ¢ncer mas foram esperadas que nÃ£o tinham, dividido pelo total de alarmes negativos.
	
	$$\frac{0}{0 + 120} = 0 = 0\% $$
	
	Houve uma probabilidade de $0\%$ de falsas omissÃµes de alarme, visto que houveram 0 casos de falsos-negativos.
	
---------------------------------------------------------------------------------------------------------------------------------------
	
	BÃ´nus: Podemos criar uma funÃ§Ã£o pra calcular essas medidas automaticamente: 
	
	\begin{lstlisting}[style=mystyle, language=Scilab]
function [acuracia, precisao, recall, falsoalarme, falsaomisao]=medidas(VP, VN, FN, FP)

total = (VP + VN + FN + FP);
acuracia = (VP + VN)/ total;
precisao = VP / (VP + FP);
recall = VP / (VP + FN);
falsoalarme = FP / (VP + FP);
falsaomisao = FN / (FN + VN);

endfunction
	\end{lstlisting}

---------------------------------------------------------------------------------------------------------------------------------------
	Testando a funÃ§Ã£o para os dados de teste: (jÃ¡ calculado)
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\linewidth]{figures/medidas1}
	\end{figure}
	
---------------------------------------------------------------------------------------------------------------------------------------
	Analogamente, podemos calcular os valores da matriz de confusÃ£o da tabela de treinamento:
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.7\linewidth]{figures/check2}
	\end{figure}

	\begin{figure}[H]
		\centering
		\includegraphics[width=1\linewidth]{figures/matriz_de_confusao2}
	\end{figure}

	Encontrando as medidas para os dados de treinamento:
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\linewidth]{figures/medidas2}
	\end{figure}

	$\cdot$ \textbf{{\normalsize AcurÃ¡cia:}} = 0.93 = $93\%$\\
	$\cdot$ \textbf{{\normalsize PrecisÃ£o:}} = 0.9310345 = $93.1\%$\\
	$\cdot$ \textbf{{\normalsize Recall ou RevocaÃ§Ã£o:}} = 0.9246575 = $92.4\%$\\
	$\cdot$ \textbf{{\normalsize Falso Alarme:}} = 0.0689655 = $6.8\%$\\
	$\cdot$ \textbf{{\normalsize Falsa OmissÃ£o de Alarme:}} = 0.0709677 = $7.09\%$\\
	
	Logo Ã  primeira vista, nota-se uma diferenÃ§a em relaÃ§Ã£o Ã s medidas da tabela de testes, apesar da probabilidade de falsa omissÃ£o de alarme ser maior, os resultados foram mais consistentes. Isso se dÃ¡ especialmente pela boa precisÃ£o do $alfa\_tr$ nestes pacientes, onde conseguiu prever muito melhor quem realmente tinha cÃ¢ncer.
\end{enumerate}
\end{document}