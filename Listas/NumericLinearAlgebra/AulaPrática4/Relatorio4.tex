\documentclass[leqno]{article}
\usepackage[utf8x]{inputenc}
\usepackage{float}
\usepackage[brazil]{babel} %\usepackage[latin1]{inputenc}
\usepackage{a4wide}
\usepackage{mathtools}
\usepackage{nccmath}
\setlength{\oddsidemargin}{-0.2in}
% % \setlength{\oddsidemargin}{0.2in}
\setlength{\evensidemargin}{-0.2in}
% % \setlength{\evensidemargin}{0.5in}
% % \setlength{\textwidth}{5.5in}
\setlength{\textwidth}{6.5in}
\setlength{\topmargin}{-1.2in}
\setlength{\textheight}{10in}
\usepackage[]{amsfonts} \usepackage[]{amsmath}
\usepackage[]{amssymb} \usepackage[]{latexsym}
\usepackage{graphicx,color} \usepackage{amsthm}
\usepackage{mathrsfs} \usepackage{url}
\usepackage{cancel} \usepackage{enumerate}
\usepackage{xifthen} \usepackage{tikz}
\usetikzlibrary{automata,arrows,positioning,calc}
\usepackage{listings}
\usepackage{tcolorbox}
\numberwithin{equation}{section}

\setlength{\parindent}{12 pt}

\definecolor{codegray}{rgb}{0.9, 0.9, 0.9}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{codegreen}{rgb}{0,0.6,0}

\lstdefinestyle{mystyle}{
	language=Scilab,
	backgroundcolor=\color{codegray},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	emph={testfunc,print,src},
	emphstyle=\color{codeyellow},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}

\lstset{style=mystyle}

\begin{document}
	
	\newtheorem{teo}{Teorema}[section] \newtheorem*{teo*}{Teorema}
	\newtheorem{prop}[teo]{Proposi√ß√£o} \newtheorem*{prop*}{Proposi√ß√£o}
	\newtheorem{lema}[teo]{Lemma} \newtheorem*{lema*}{Lema}
	\newtheorem{cor}[teo]{Corol√°rio} \newtheorem*{cor*}{Corol√°rio}
	
	\theoremstyle{definition}
	\newtheorem{defi}[teo]{Defini√ß√£o} \newtheorem*{defi*}{Defini√ß√£o}
	\newtheorem{exem}[teo]{Exemplo} \newtheorem*{exem*}{Exemplo}
	\newtheorem{obs}[teo]{Observa√ß√£o} \newtheorem*{obs*}{Observa√ß√£o}
	\newtheorem*{hipo}{Hip√≥teses}
	\newtheorem*{nota}{Nota√ß√£o}
	
	\newcommand{\ds}{\displaystyle} \newcommand{\nl}{\newline}
	\newcommand{\eps}{\varepsilon} \newcommand{\ssty}{\scriptstyle}
	\newcommand{\bE}{\mathbb{E}}
	\newcommand{\cB}{\mathcal{B}}
	\newcommand{\cF}{\mathcal{F}}
	\newcommand{\cA}{\mathcal{A}}
	\newcommand{\cM}{\mathcal{M}}
	\newcommand{\cD}{\mathcal{D}}
	\newcommand{\cN}{\mathcal{N}}
	\newcommand{\cL}{\mathcal{L}}
	\newcommand{\cLN}{\mathcal{LN}}
	\newcommand{\bP}{\mathbb{P}}
	\newcommand{\bQ}{\mathbb{Q}}
	\newcommand{\bN}{\mathbb{N}}
	\newcommand{\bR}{\mathbb{R}}
	\newcommand{\bZ}{\mathbb{Z}}
	
	\newcommand{\bfw}{\mathbf{w}}
	\newcommand{\bfv}{\mathbf{v}}
	\newcommand{\bfu}{\mathbf{u}}
	\newcommand{\bfx}{\mathbf{x}}
	\newcommand{\bfb}{\mathbf{b}}
	
	\newcommand{\bvecc}[2]{%
		\begin{bmatrix} #1 \\ #2  \end{bmatrix}
	}
	\newcommand{\bveccc}[3]{%
		\begin{bmatrix} #1 \\ #2 \\ #3  \end{bmatrix}
	}
	
	\newenvironment{sol} 
	{
		\vspace{4mm}
		\noindent\textbf{{\large C√≥digo:}}
		\strut\newline
		\smallskip
		\hspace{-3.5mm} 
	} 
	% Objetos que aparecem *ap√≥s* o ambiente. 
	% (voc√™ pode, por exemplo, modificar, 
	% ou remover, a barra horizontal} 
	%{\noindent\rule{4cm}{.1mm}}
	
	
	\title{√Ålgebra Linear - Aula Pr√°tica 4}
	
	\author{Iara Cristina Mescua Castro}
	
	\date{\today}
	
	\maketitle 
	
	\begin{enumerate}
		
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		%%%%%%%%%%%%%%%%%%%%%% Exerc√≠cio 1 %%%%%%%%%%%%%%%%%%%%%%
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		
		\item  \textbf{{\large M√âTODO DOS M√çNIMOS QUADRADOS}}\\
	
		
		\begin{tcolorbox}[colback=green!5,colframe=green!40!black]
			1) (Texto do livro C√°lculo - Volume 2 ‚Äì James Stewart) Em 1928, Charles
			Cobb e Paul Douglas publicaram um estudo no qual modelaram o
			crescimento da economia norte-americana durante o per√≠odo de 1899-
			1922. Eles consideraram uma vis√£o simplificada da economia em que a
			sa√≠da da produ√ß√£o √© determinada pela quantidade de trabalho envolvido e
			pela quantidade de capital investido. Apesar de existirem muitos outros
			fatores afetando o desempenho da economia, o modelo mostrou-se
			bastante preciso. A fun√ß√£o utilizada para modelar a produ√ß√£o era da forma:
			
			$$ùëÉ = bL^{\alpha}K^{1 - \alpha}$$
			
			onde P √© a produ√ß√£o total (valor monet√°rio dos bens produzidos no ano);
			L √© a quantidade de trabalho (n√∫mero total de pessoas-hora trabalhadas no
			ano); e K √© a quantidade de capital investido (valor monet√°rio das
			m√°quinas, equipamentos e pr√©dios); b e $\alpha$ s√£o par√¢metros (constantes) a
			serem determinados.
			Cobb e Douglas usaram os dados da tabela a seguir e o M√©todo dos
			M√≠nimos Quadrados para obter os valores de b e de $\alpha$.
		\end{tcolorbox}
		
		\begin{tcolorbox}[colback=gray!5,colframe=gray!40!black]	
			a) Fa√ßa como Cobb e Douglas: use o M√©todo dos M√≠nimos Quadrados
			para estimar os valores dos par√¢metros b e $\alpha$. Mostre a sua modelagem
			para o problema ser resolvido pelo M√©todo dos M√≠nimos Quadrados.
		\end{tcolorbox}		
	
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		%%%%%%%%%%%%%%%%%%%%%% ALGORITMO 1 %%%%%%%%%%%%%%%%%%%%%%
		%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
		
		\textbf{{\normalsize DESENVOLVIMENTO}}
		
		Queremos encontrar b e $\alpha$ a partir da f√≥rmula, ent√£o para isso vamos tentar isol√°-los:
		$$ùëÉ = bL^{\alpha}K^{1 - \alpha}$$
		Calculando logaritmo da equa√ß√£o:
		$$ln(ùëÉ) = ln(b) + \alpha ln(L) + (1-\alpha)ln(K)$$
		$$ln(ùëÉ) = ln(b) + \alpha ln(L) + ln(K) - \alpha ln(K)$$
		$$ln(ùëÉ) - ln(K) = ln(b) + \alpha ln(L) - \alpha ln(K)$$
		
		$$ln(b) + \alpha (ln(L) - ln(K)) = ln(ùëÉ) - ln(K)$$
		
		Para utilizar o m√©todo dos m√≠nimos quadrados, precisamos de express√£o na forma $Ax = b$.
		Podemos observar que $ln(b)$ n√£o est√° multiplicando com ningu√©m, ent√£o podemos colocar uma coluna de 1 na frente de $A = (ln(L) - ln(K))$ para represent√°-la da seguinte forma:
		
		
		$$\begin{bmatrix}
			1 & (ln(L) - ln(K))^1 \\
			1 & \vdots \\
			1 & (ln(L) - ln(K))^{24}
		\end{bmatrix}
		\begin{bmatrix}
			ln(b) \\
			\alpha
		\end{bmatrix} = \begin{bmatrix}
			(ln(P) - ln(K))^1 \\
			\vdots \\
			(ln(P) - ln(K))^{24}
		\end{bmatrix}$$
	
	Agora podemos aplicar o m√©todo dos m√≠nimos quadrados, onde:
	
	$$A = \begin{bmatrix}
		1 & (ln(L) - ln(K))^1 \\
		1 & \vdots \\
		1 & (ln(L) - ln(K))^{24}
	\end{bmatrix}$$

	$$x = \begin{bmatrix}
		ln(b) \\
		\alpha
	\end{bmatrix}$$

	$$b = \begin{bmatrix}
		(ln(P) - ln(K))^1 \\
		\vdots \\
		(ln(P) - ln(K))^{24}
	\end{bmatrix}$$

	Logo:
	
		$$ln(b) + \alpha (ln(L) - ln(K)) = ln(ùëÉ) - ln(K)$$
		
		$$Ax = b$$
		
	Criando uma fun√ß√£o que receba a planilha de dados e separe as colunas K, L e P para transform√°-las nas matrizes A e b do sistema, e por fim, calcular a solu√ß√£o x que melhor aproxima esses dados atrav√©s do m√©todo dos m√≠nimos quadrados:
	
	$$A^TAx = A^Tb$$
	
	Lembrando que ao encontrar x, teremos os valores de $ln(b)$ e $\alpha$, $$x = \begin{bmatrix}
		ln(b) \\
		\alpha
	\end{bmatrix}$$
	Ent√£o para retornar b, basta elevar o primeiro valor do vetor x, $ln(b)$ a exponencial:
	
\begin{sol}			
	\begin{lstlisting}[style=mystyle, language=Scilab]
	function [alfa, b]=calcular_alfa_b(A)
	
	P = A(:,2);
	L = A(:,3);
	K = A(:,4);
	
	P_ln = log(P);
	L_ln = log(L);
	K_ln = log(K);
	
	n = size(L,1);
	A = [ones(n,1) (L_ln - K_ln)];
	b = (P_ln - K_ln);
	//nao esquecer de executar a funcao Gaussian_Elimination_4
	x = Gaussian_Elimination_4(A' * A, A' * b);
	alfa = x(2);
	b = exp(x(1));
	endfunction
	\end{lstlisting}
	\newpage
	Ao testar a fun√ß√£o na tabela:
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.7\linewidth]{figures/tabela}
	\end{figure}

	\begin{figure}[H]
		\centering
		\includegraphics[width=0.4\linewidth]{figures/1a}
	\end{figure}

	Encontramos que:\\
	$\cdot$ $\alpha = 0.7446062$\\
	$\cdot$ $b = 1.0070689$
	\begin{tcolorbox}[colback=gray!5,colframe=gray!40!black]	
		b) Agora, use a fun√ß√£o de Cobb-Douglas encontrada no item a) e teste a
		sua adequa√ß√£o calculando os valores da produ√ß√£o nos anos de 1910 e
		1920. Comente!
	\end{tcolorbox}
	
	Agora que temos os valores de $\alpha$ e b, podemos substitu√≠-los na f√≥rmula de produ√ß√£o para encontrar a previs√£o de P. Para isso criei uma fun√ß√£o que recebe a tabela de dados, e verifica o ano de entrada para escolher os valores de K e L em suas respectivas colunas, e por √∫ltimo, substituir na f√≥rmula.
	
	\begin{lstlisting}[style=mystyle, language=Scilab]
function [P]=calcular_p(A, ano)

L = A(:,3); //L na coluna 3
K = A(:,4); //K na coluna 4

n = size(K,1) 
for i = 1:n
	if (A(i,1) == ano) //verifica a linha do ano selecionado
		x = A(i,:);
		L = x(3);
		K = x(4);
		//funcao utilizada para modelar a producao
		P = b * L^alfa * K^(1-alfa); 
	end
end
endfunction
	\end{lstlisting}
\end{sol}

Os valores de \textit{alfa} e \textit{b} n√£o precisam estar na entrada, pois as vari√°veis no scilab s√£o globais, basta haver executado $[alfa, b]=calcular\_alfa\_b(A)$ anteriormente. Da seguinte forma, podemos encontrar os valores de P nos anos de 1910 e 1920, e em qualquer outro ano desejado.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.4\linewidth]{figures/1b}
\end{figure}

Os valores previstos para P foram:\\
$\cdot$ $P_{1910} = 161.76185$\\
$\cdot$ $P_{1920} = 236.07215$\\

Os valores reais de P nesses anos foram:\\
$\cdot$ $P_{1910} = 159$\\
$\cdot$ $P_{1920} = 231$\\

Podemos concluir que os valores de $\alpha$ e $b$ calculam a produ√ß√£o de forma relativamente precisa. Vamos calcular mais alguns anos:

\begin{figure}[H]
	\centering
	\includegraphics[width=0.3\linewidth]{figures/1btestes}
\end{figure}
\newpage
Os valores previstos para P foram:\\
$\cdot$ $P_{1900} = 106.25302$\\
$\cdot$ $P_{1905} = 131.65873$\\
$\cdot$ $P_{1915} = 180.04169$\\
$\cdot$ $P_{1918} = 235.90134$\\

Os valores reais de P nesses anos foram:\\
$\cdot$ $P_{1900} = 101$\\
$\cdot$ $P_{1905} = 143$\\
$\cdot$ $P_{1915} = 189$\\
$\cdot$ $P_{1918} = 223$\\

De forma geral, a previs√£o est√° proxima, h√° um erro de mais ou menos 10. Segue o gr√°fico feito em excel dos valores reais de produ√ß√£o juntamente com os valores obtidos da fun√ß√£o de previs√£o ao longo dos anos:

\begin{figure}[H]
	\centering
	\includegraphics[width=1.1\linewidth]{figures/excel}
\end{figure}

Ao comparar a linha de tend√™ncia dos valores previstos de produ√ß√£o com a dos valores reais, nota-se que com o passar dos anos a precis√£o vai diminuindo.
 \newpage
\item  \textbf{{\large ‚ÄúMACHINE LEARNING‚Äù}}\\

\begin{tcolorbox}[colback=green!5,colframe=green!40!black]
	2) Agora vamos usar o m√©todo dos m√≠nimos quadrados para implementar um
	m√©todo rudimentar de ‚Äúmachine learning‚Äù para diagnosticar c√¢ncer de
	mama a partir de um conjunto de caracter√≠sticas fornecidas para cada
	paciente. S√£o dados dois arquivos: um arquivo para ‚Äútreinamento‚Äù
	(cancer\_train.csv) do modelo e um arquivo para ‚Äúteste‚Äù (cancer\_test.csv).
	O primeiro arquivo cont√©m 300 registros e o segundo 260 registros, partes
	do ‚ÄúWiscosin Diagnostic Breast Cancer dataset‚Äù. Cada registro de cada
	arquivo cont√©m 11 valores: os 10 primeiros correspondem a valores reais
	de 10 caracter√≠sticas dos n√∫cleos celulares observados em imagens
	digitalizadas de uma fina camada de massa mam√°ria coletada de cada
	paciente. O d√©cimo primeiro valor √© +1 se a paciente tem c√¢ncer de mama
	e -1, caso contr√°rio.
	Sendo x o vetor das 10 caracter√≠sticas de cada paciente (vari√°veis
	independentes) e y o valor (+1 ou -1) que indica o diagn√≥stico (vari√°vel
	dependente), a ideia √©, usando o arquivo de treinamento, obter o hiperplano
	y = h(x) que ‚Äúmelhor se ajuste aos dados fornecidos‚Äù usando o m√©todo dos m√≠nimos quadrados.
	Uma vez obtido o hiperplano, o mesmo ser√° usado para classificar cada
	paciente da seguinte forma: se $h(x) \geq 0$, ent√£o o diagn√≥stico √© +1 (tem
	c√¢ncer), caso contr√°rio, o diagn√≥stico √© ‚àí1 (n√£o tem c√¢ncer).
	Use o seu classificador (hiperplano) e calcule a porcentagem de acertos
	sobre o arquivo de treinamento (de certa forma √© uma medida do ajuste do
	seu modelo aos dados de treinamento) e sobre o arquivo de teste (de certa
	forma √© uma medida da capacidade de generaliza√ß√£o do seu modelo).
	Construa uma Matriz de Confus√£o (Confusion Matrix) (pesquise a respeito)
	com o conjunto de teste e calcule as diversas medidas da√≠ decorrentes, tais
	como: acur√°cia, precis√£o, recall, probabilidade de falso alarme,
	probabilidade de falsa omiss√£o de alarme. Interprete essas medidas e
	comente os resultados obtidos.
\end{tcolorbox}	

Para essa quest√£o vamos precisar classificar os pacientes da tabela de testes atrav√©s de previs√µes seguindo o classificador h(x). Ele prov√©m do $alfa\_tr$ que ser√° calculado pela tabela de treinamento.

Para calcular $alfa\_tr$, criei uma fun√ß√£o $[alfa\_barra]=Encontra\_alfa\_barra(x\_tr, y\_tr)$ que encontra uma solu√ß√£o aproximada resolvendo o sistema linear Ax = b pelo m√©todo dos m√≠nimos quadrados, onde:

$$A = x_tr' * x_tr$$

$$b = x_tr' * y_tr$$

Ent√£o para isso, precisamos encontrar $x\_tr$ e $y\_tr$ primeiro.\\
Calculando todos os dados necess√°rios, juntamente com o alfa: $y\_tr, y\_tt, x\_tr, x\_tt, alfa\_tr, h\_tr$:\\

\begin{sol}
	\begin{lstlisting}[style=mystyle, language=Scilab]
function [y_tr, y_tt, x_tr, x_tt, alfa_tr, h_tr]=dados(A_tr, A_tt)
n = size(A_tr,2);

y_tr = A_tr(:,n);
y_tt = A_tt(:,n);

x_tr = [ones(y_tr) A_tr(:,1:n - 1)];
x_tt = [ones(y_tt) A_tt(:,1:n - 1)];

alfa_tr =Encontra_alfa_barra(x_tr, y_tr);
h_tr = x_tr * alfa_tr;
endfunction

function [alfa_barra]=Encontra_alfa_barra(x_tr, y_tr)
alfa_barra = Gaussian_Elimination_4(x_tr' * x_tr, x_tr' * y_tr);
endfunction
\end{lstlisting}	

Agora j√° obtemos $alfa\_tr$ e podemos encontrar as previs√µes para a tabela de testes (e treinamento, para compara√ß√£o), que j√° teve seus $x\_tt$ e $y\_tt$ obtidos na fun√ß√£o anterior $[y\_tr, y\_tt, x\_tr, x\_tt, alfa\_tr, h\_tr]=dados(A\_tr, A\_tt)$:

Agora com outra fun√ß√£o de encontrar o n√∫mero de acertos, multiplicamos $x\_tr$ e $x\_tt$ pelo $alfa\_tr$ obtido.
Para conferir essa previs√£o, basta multiplicar ela pelos resultados reais. Lembrando que se a previs√£o est√° certa, teremos
pacientes doentes (+1) sendo classificados com um valor \textbf{positivo}, e pacientes n√£o-doentes (-1) sendo classificados com um valor \textbf{negativo}. 

Note que em ambos casos em que a previs√£o funciona os sinais s√£o iguais, logo, o seu produto sempre ser√° positivo. Ao multiplicar esses dois valores: $prev\_tr$ e $prev\_tt$ por $y\_tr$ e $y\_tt$, respectivamente, podemos conferir se a previs√£o est√° correta, checando quantos deles s√£o positivos.

A fun√ß√£o seguinte calcula a previs√£o e o n√∫mero de acertos da tabela de treinamento e da tabela de testes:
\begin{lstlisting}[style=mystyle, language=Scilab]
[prev_tr,prev_tt,acertos_tr, acertos_tt]=acertos(x_tr, x_tt, alfa_tr)
prev_tr = x_tr*alfa_tr;
prev_tt = x_tt*alfa_tr;

conf_prev_tr = prev_tr .*y_tr;
conf_prev_tt = prev_tt .*y_tt;

acertos_tr = sum(conf_prev_tr > 0 | conf_prev_tr == 0);
acertos_tt = sum(conf_prev_tt > 0 | conf_prev_tt == 0);
endfunction
\end{lstlisting}

Testando ambas fun√ß√µes, primeiro encontramos os dados necess√°rios e depois calculamos os acertos com a fun√ß√£o acima:

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{figures/2.1}
\end{figure}

Conclu√≠mos que com $alfa\_tr$ teve 289 acertos de 300 casos na tabela de treinamento, enquanto na tabela de testes teve apenas 185 acertos de 260 casos.

Note que $y\_tt$, $y\_tr$, $prev\_tt$ e $prev\_tt$ n√£o foram utilizados ainda, mas ser√£o importantes para encontrar a matriz de confus√£o.

	\item  \textbf{{\large MATRIZ DE CONFUS√ÉO}}\\
	
	Para encontrar a matriz de confus√£o, optei tamb√©m por criar uma fun√ß√£o que gerasse cada valor a partir das previs√µes do teste \textit{'prev\_tt'} e os resultados reais em \textit{'y\_tt'}
	
	Sabemos que cada caso na previs√£o mant√©m a ordem dos valores obtidos da planilha de dados, ent√£o basta usar cada √≠ndice para comparar se o seu valor em \textit{'prev\_tt'} √© maior ou menor que 0, e checar se naquele √≠ndice de \textit{'y\_tt'} √© igual a +1 ou -1.
	
	$\cdot$ VP: $h(x) > 0$ e y(i) = 1 \\
	$\cdot$ VN: $h(x) < 0$ e y(i) = -1\\
	$\cdot$ FN: $h(x) > 0$ e y(i) = -1\\
	$\cdot$ FP: $h(x) < 0$ e y(i) = 1 \\
\newpage
	\begin{lstlisting}[style=mystyle, language=Scilab]
function [VP, VN, FN, FP]=check(prev_tt, y_tt)

[VP]=check_pos(prev_tt, y_tt); //verdadeiro positivo: 1
[VN]=check_neg(prev_tt, y_tt); //verdadeiro negativo: 2
[FN]=check_neg_pos(prev_tt, y_tt); //falso negativo: 3
[FP]=check_pos_neg(prev_tt, y_tt); //falso positivo: 4

endfunction

function [VP]=check_pos(prev_tt, y_tt) //1: diz que tem, e tem mesmo
n = size(prev_tt, 1);
VP = 0;
for i = 1:n
	if (prev_tt(i) > 0 & y_tt(i) == 1)
		VP = VP + 1;
	end
end
endfunction

function [VN]=check_neg(prev_tt, y_tt) //2: diz que nao tem, e nao tem
n = size(prev_tt, 1);
VN = 0;
for i = 1:n
	if (prev_tt(i) < 0 & y_tt(i) == -1)
		VN = VN + 1;
	end
end
endfunction

function [FN]=check_neg_pos(prev_tt, y_tt) //3: diz que tem, mas nao tem
n = size(prev_tt, 1);
FN = 0;
for i = 1:n
	if (prev_tt(i) > 0 & y_tt(i) == -1)
		FN = FN + 1;
	end
end
endfunction

function [FP]=check_pos_neg(prev_tt, y_tt) //4: diz que nao tem, mas tem 
n = size(prev_tt, 1);
FP = 0;
for i = 1:n
	if (prev_tt(i) < 0 & y_tt(i) == 1)
		FP = FP + 1;
	end
end
endfunction
	\end{lstlisting}	
\end{sol}

	\begin{figure}[H]
		\centering
		\includegraphics[width=0.7\linewidth]{figures/check}
	\end{figure}
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=1\linewidth]{figures/matriz_de_confusao}
	\end{figure}

	Com essa matriz, podemos calcular outras medidas e fazer algumas an√°lises:
	
	$\cdot$ \textbf{{\large Acur√°cia:}}
	O c√°lculo da acur√°cia se d√° pela f√≥rmula: $\frac{VP + VN}{total}$, ou seja, o total de acertos (soma da diagonal da matriz) dividido pelo total:
	
	$$\frac{185}{260} = 0.7115385 = 71.1\% $$
	
	$\cdot$ \textbf{{\large Precis√£o:}} 
	O c√°lculo da precis√£o se d√° pela f√≥rmula: $\frac{VP}{VP + FP}$, ou seja, o total de acertos/alarmes de pessoas doentes pelo total de pessoas doentes esperadas pela previs√£o:
	
	$$\frac{60}{60 + 75} = 0.4444444 = 44.4\% $$
	
	Houve $44\%$, ou seja, de todas as pessoas esperadas doentes, um pouco mais da metade delas, na verdade n√£o tinha c√¢ncer. A precis√£o na matriz de testes foi baixa.
	
	$\cdot$ \textbf{{\large Recall ou Revoca√ß√£o:}} 
	O c√°lculo da recall se d√° pela f√≥rmula: $\frac{VP}{VP + FN}$, ou seja, o total de acertos/alarmes de pessoas doentes pelo total de pessoas que realmente est√£o doentes:
	
	$$\frac{60}{60 + 0} = 1 = 100\% $$
	
	Houve $100\%$ de precis√£o, isso significa que a previs√£o n√£o deu negativo $NENHUMA$ vez para algu√©m que realmente tinha c√¢ncer. 
	
	$\cdot$ \textbf{{\large Falso Alarme:}}
	O c√°lculo de falso alarme se d√° pela f√≥rmula: $\frac{FP}{VP + FP}$, ou seja, o total de pessoas que foram esperadas com c√¢ncer, mas na verdade n√£o tinham, dividido pelo total de alarmes positivos.
	
	$$\frac{75}{75 + 60} = 0.5555556 = 55.5\% $$
	
	Houve $55\%$ de probabilidade de falsos alarmes, ou seja, cerca de metade das pessoas esperadas com c√¢ncer pela previs√£o, na verdade n√£o tinham c√¢ncer. Note que a probabilidade de falso alarme √© complementar √† precis√£o.
	
	$\cdot$ \textbf{{\large Falsa Omiss√£o de Alarme:}} 
	O c√°lculo da falsa omiss√£o de alarme se d√° pela f√≥rmula: $\frac{FN}{FN + VN}$, ou seja, o total de pessoas que tinham c√¢ncer mas foram esperadas que n√£o tinham, dividido pelo total de alarmes negativos.
	
	$$\frac{0}{0 + 120} = 0 = 0\% $$
	
	Houve uma probabilidade de $0\%$ de falsas omiss√µes de alarme, visto que houveram 0 casos de falsos-negativos.
	
---------------------------------------------------------------------------------------------------------------------------------------
	
	B√¥nus: Podemos criar uma fun√ß√£o pra calcular essas medidas automaticamente: 
	
	\begin{lstlisting}[style=mystyle, language=Scilab]
function [acuracia, precisao, recall, falsoalarme, falsaomisao]=medidas(VP, VN, FN, FP)

total = (VP + VN + FN + FP);
acuracia = (VP + VN)/ total;
precisao = VP / (VP + FP);
recall = VP / (VP + FN);
falsoalarme = FP / (VP + FP);
falsaomisao = FN / (FN + VN);

endfunction
	\end{lstlisting}

---------------------------------------------------------------------------------------------------------------------------------------
	Testando a fun√ß√£o para os dados de teste: (j√° calculado)
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\linewidth]{figures/medidas1}
	\end{figure}
	
---------------------------------------------------------------------------------------------------------------------------------------
	Analogamente, podemos calcular os valores da matriz de confus√£o da tabela de treinamento:
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.7\linewidth]{figures/check2}
	\end{figure}

	\begin{figure}[H]
		\centering
		\includegraphics[width=1\linewidth]{figures/matriz_de_confusao2}
	\end{figure}

	Encontrando as medidas para os dados de treinamento:
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=0.8\linewidth]{figures/medidas2}
	\end{figure}

	$\cdot$ \textbf{{\normalsize Acur√°cia:}} = 0.93 = $93\%$\\
	$\cdot$ \textbf{{\normalsize Precis√£o:}} = 0.9310345 = $93.1\%$\\
	$\cdot$ \textbf{{\normalsize Recall ou Revoca√ß√£o:}} = 0.9246575 = $92.4\%$\\
	$\cdot$ \textbf{{\normalsize Falso Alarme:}} = 0.0689655 = $6.8\%$\\
	$\cdot$ \textbf{{\normalsize Falsa Omiss√£o de Alarme:}} = 0.0709677 = $7.09\%$\\
	
	Logo √† primeira vista, nota-se uma diferen√ßa em rela√ß√£o √†s medidas da tabela de testes, apesar da probabilidade de falsa omiss√£o de alarme ser maior, os resultados foram mais consistentes. Isso se d√° especialmente pela boa precis√£o do $alfa\_tr$ nestes pacientes, onde conseguiu prever muito melhor quem realmente tinha c√¢ncer.
\end{enumerate}
\end{document}